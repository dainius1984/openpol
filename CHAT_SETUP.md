# ğŸš€ Konfiguracja OpenPol Chat

## Opcje integracji chatu

Masz 3 opcje podpiÄ™cia chatu:

### âœ… Opcja 1: OpenAI API (Najprostsze - Rekomendowane)

**Krok 1:** ZdobÄ…dÅº klucz API
1. Zarejestruj siÄ™ na https://platform.openai.com/
2. PrzejdÅº do sekcji API Keys
3. UtwÃ³rz nowy klucz API
4. Skopiuj klucz (zaczyna siÄ™ od `sk-`)

**Krok 2:** Skonfiguruj backend
```bash
cd backend
cp env.example .env
```

Edytuj plik `.env` i dodaj swÃ³j klucz:
```env
OPENAI_API_KEY=sk-twoj-klucz-tutaj
OPENAI_MODEL=gpt-3.5-turbo
```

**Krok 3:** Zainstaluj zaleÅ¼noÅ›ci
```bash
pip install -r requirements.txt
```

**Krok 4:** Uruchom backend
```bash
python server.py
```

Backend bÄ™dzie dostÄ™pny na `http://localhost:5000`

**Koszty:** ~$0.01 za 10 wiadomoÅ›ci (masz $5 darmowych kredytÃ³w na start)

---

### âœ… Opcja 2: Ollama (Lokalny model - Darmowy)

**Krok 1:** Zainstaluj Ollama
- Windows: Pobierz z https://ollama.com/download
- Mac/Linux: `curl https://ollama.ai/install.sh | sh`

**Krok 2:** Uruchom model
```bash
ollama run llama2
```

**Krok 3:** Skonfiguruj backend
```bash
cd backend
cp env.example .env
```

Edytuj `.env`:
```env
USE_OLLAMA=true
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama2
```

**Krok 4:** Zainstaluj zaleÅ¼noÅ›ci i uruchom
```bash
pip install -r requirements.txt
python server.py
```

**Koszty:** Darmowe (dziaÅ‚a lokalnie)

---

### âœ… Opcja 3: Mock Responses (Bez API - tylko testy)

JeÅ›li nie skonfigurujesz Å¼adnego API, backend automatycznie uÅ¼yje prostych odpowiedzi mockowych. DziaÅ‚a od razu bez konfiguracji, ale odpowiedzi sÄ… bardzo podstawowe.

---

## ğŸ¯ Uruchomienie caÅ‚ej aplikacji

**Terminal 1 - Backend:**
```bash
cd backend
python server.py
```

**Terminal 2 - Frontend:**
```bash
npm start
```

Teraz moÅ¼esz:
1. OtworzyÄ‡ http://localhost:3000
2. KliknÄ…Ä‡ "WyprÃ³buj OpenPol Chat"
3. RozmawiaÄ‡ z chatem! ğŸ’¬

---

## ğŸ”§ Troubleshooting

### Backend nie startuje
- SprawdÅº czy Python 3.8+ jest zainstalowany: `python --version`
- SprawdÅº czy wszystkie zaleÅ¼noÅ›ci sÄ… zainstalowane: `pip install -r requirements.txt`
- SprawdÅº czy port 5000 jest wolny

### Chat nie odpowiada
- SprawdÅº czy backend dziaÅ‚a: otwÃ³rz http://localhost:5000/api/health
- SprawdÅº konsole przeglÄ…darki (F12) czy sÄ… bÅ‚Ä™dy
- SprawdÅº czy klucz API jest poprawny (dla OpenAI)

### BÅ‚Ä…d CORS
- Upewnij siÄ™ Å¼e backend ma `CORS(app)` w kodzie
- SprawdÅº czy frontend uÅ¼ywa poprawnego URL: `REACT_APP_CHAT_API_URL=http://localhost:5000`

---

## ğŸ“ Pliki konfiguracyjne

- `backend/.env` - zmienne Å›rodowiskowe backendu (utwÃ³rz z `env.example`)
- `.env` (gÅ‚Ã³wny folder) - zmienne Å›rodowiskowe frontendu

Frontend `.env`:
```env
REACT_APP_CHAT_API_URL=http://localhost:5000
REACT_APP_GA_MEASUREMENT_ID=G-XXXXXXXXXX
```

---

## ğŸ’¡ WskazÃ³wki

1. **Dla produkcji:** UÅ¼yj OpenAI API, jest najstabilniejsze
2. **Dla rozwoju:** MoÅ¼esz uÅ¼yÄ‡ Ollama lub mock responses
3. **BezpieczeÅ„stwo:** Nigdy nie commituj plikÃ³w `.env` z kluczami API
4. **Koszty:** Monitoruj uÅ¼ycie OpenAI API w dashboardzie

---

## âœ… Testowanie

Po skonfigurowaniu:

1. Uruchom backend: `python backend/server.py`
2. Uruchom frontend: `npm start`
3. OtwÃ³rz http://localhost:3000/chat
4. Napisz "CzeÅ›Ä‡!" i sprawdÅº odpowiedÅº

JeÅ›li wszystko dziaÅ‚a, zobaczysz odpowiedÅº od AI! ğŸ‰

